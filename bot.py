import os
import re
import math
import asyncio
import random
import requests
from collections import deque
from telethon import TelegramClient, events
from telethon.sessions import StringSession
from telethon.tl.functions.upload import SaveBigFilePartRequest
from telethon.tl.functions.messages import SendMediaRequest
from telethon.tl.types import (
    InputFileBig,
    InputMediaUploadedDocument,
    DocumentAttributeFilename,
)

# â”€â”€ ENV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_ID         = int(os.environ["TG_API_ID"])
API_HASH       = os.environ["TG_API_HASH"]
BOT_TOKEN      = os.environ["BOT_TOKEN"]
OWNER_ID       = int(os.environ["OWNER_ID"])
STRING_SESSION = os.environ.get("STRING_SESSION")

# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PART_SIZE  = 1990 * 1024 * 1024
CHUNK_SIZE = 512 * 1024
CONCURRENT = 6
UA         = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
WORK_DIR   = "/tmp/gofile_dl"

os.makedirs(WORK_DIR, exist_ok=True)

# â”€â”€ Clients â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if STRING_SESSION:
    user_client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
else:
    user_client = TelegramClient("user_session", API_ID, API_HASH)

bot_client = TelegramClient("bot_session", API_ID, API_HASH)

# â”€â”€ Queue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
job_queue     = deque()
queue_urls    = set()
worker_task   = None   # single worker reference


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GoFile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_website_token() -> str:
    r = requests.get(
        "https://gofile.io/dist/js/config.js",
        headers={"User-Agent": UA}, timeout=15
    )
    r.raise_for_status()
    js = r.text
    if 'appdata.wt = "' in js:
        return js.split('appdata.wt = "')[1].split('"')[0]
    for pat in [
        r'websiteToken["\']?\s*[=:]\s*["\']([^"\']{4,})["\']',
        r'"wt"\s*:\s*"([^"]{4,})"',
    ]:
        m = re.search(pat, js)
        if m:
            return m.group(1)
    raise Exception("GoFile websiteToken nemata.")


def resolve_gofile(page_url: str):
    cid = page_url.rstrip("/").split("/d/")[-1]
    r   = requests.post(
        "https://api.gofile.io/accounts",
        headers={"User-Agent": UA}, timeout=15
    ).json()
    if r.get("status") != "ok":
        raise Exception(f"Guest token fail: {r}")

    wt   = get_website_token()
    hdrs = {
        "Authorization":   f"Bearer {r['data']['token']}",
        "X-Website-Token": wt,
        "User-Agent":      UA,
    }
    resp = requests.get(
        f"https://api.gofile.io/contents/{cid}?cache=true",
        headers=hdrs, timeout=30
    ).json()
    if resp.get("status") != "ok":
        raise Exception(f"GoFile API: {resp.get('status')}")

    data = resp["data"]
    children = data.get("children", {})
    item = next((v for v in children.values() if v.get("type") == "file"), None)
    if not item:
        if data.get("type") == "file":
            item = data
        else:
            raise Exception("File nemata.")

    return item["link"], item["name"], item.get("size", 0), hdrs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def make_bar(pct: int, length: int = 12) -> str:
    f = int(length * pct / 100)
    return "[" + "â–ˆ" * f + "â–‘" * (length - f) + "]"


def safe_remove(path: str):
    try:
        if path and os.path.exists(path):
            os.remove(path)
    except:
        pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Download
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def download_file(url: str, fname: str, headers: dict, cb) -> str:
    path = os.path.join(WORK_DIR, fname)
    with requests.get(url, headers=headers, stream=True, timeout=120) as r:
        r.raise_for_status()
        total    = int(r.headers.get("content-length", 0))
        done     = 0
        last_pct = -10
        with open(path, "wb") as f:
            for chunk in r.iter_content(chunk_size=4 * 1024 * 1024):
                if chunk:
                    f.write(chunk)
                    done += len(chunk)
                    if total:
                        pct = int(done / total * 100)
                        if pct - last_pct >= 5:
                            last_pct = pct
                            await cb(
                                f"â¬‡ï¸ **Downloading...**\n\n"
                                f"{make_bar(pct)} {pct}%\n"
                                f"ğŸ“¦ {done//(1024**2)} MB / {total//(1024**2)} MB"
                            )
    return path


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Split
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def split_file(path: str) -> list:
    size = os.path.getsize(path)
    n    = math.ceil(size / PART_SIZE)
    if n <= 1:
        return [path]

    parts = []
    with open(path, "rb") as f:
        for i in range(n):
            pname = f"{path}.part{i+1}of{n}"
            with open(pname, "wb") as out:
                rem = PART_SIZE
                while rem > 0:
                    chunk = f.read(min(4 * 1024 * 1024, rem))
                    if not chunk:
                        break
                    out.write(chunk)
                    rem -= len(chunk)
            if os.path.exists(pname) and os.path.getsize(pname) > 0:
                parts.append(pname)

    safe_remove(path)
    return parts


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Upload
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def upload_part(file_path: str, cb, part_num: int, total_parts: int) -> InputFileBig:
    file_size    = os.path.getsize(file_path)
    file_id      = random.randint(0, 2**63)
    total_chunks = (file_size + CHUNK_SIZE - 1) // CHUNK_SIZE
    done         = [0]
    sem          = asyncio.Semaphore(CONCURRENT)

    async def upload_one(idx: int, data: bytes):
        async with sem:
            for attempt in range(3):
                try:
                    await user_client(SaveBigFilePartRequest(
                        file_id=file_id,
                        file_part=idx,
                        file_total_parts=total_chunks,
                        bytes=data,
                    ))
                    done[0] += 1
                    if done[0] % max(1, total_chunks // 20) == 0:
                        pct     = int(done[0] / total_chunks * 100)
                        done_mb = min(done[0] * CHUNK_SIZE, file_size) // (1024**2)
                        tot_mb  = file_size // (1024**2)
                        await cb(
                            f"â¬†ï¸ **Uploading part {part_num}/{total_parts}**\n\n"
                            f"{make_bar(pct)} {pct}%\n"
                            f"ğŸ“¤ {done_mb} MB / {tot_mb} MB\n"
                            f"âš¡ {CONCURRENT} concurrent chunks"
                        )
                    return
                except Exception:
                    if attempt == 2:
                        raise
                    await asyncio.sleep(2 ** attempt)

    tasks = []
    with open(file_path, "rb") as f:
        for i in range(total_chunks):
            data = f.read(CHUNK_SIZE)
            if not data:
                break
            tasks.append(upload_one(i, data))

    await asyncio.gather(*tasks)
    return InputFileBig(id=file_id, parts=total_chunks, name=os.path.basename(file_path))


async def upload_all_parts(parts: list, original_name: str, cb):
    total = len(parts)
    for i, p in enumerate(parts, 1):
        size_mb = os.path.getsize(p) // (1024**2)
        await cb(
            f"â¬†ï¸ **Uploading part {i}/{total}**\n\n"
            f"{make_bar(0)} 0%\n"
            f"ğŸ“¤ 0 MB / {size_mb} MB\n"
            f"âš¡ {CONCURRENT} concurrent chunks"
        )
        input_file = await upload_part(p, cb, i, total)
        await user_client(SendMediaRequest(
            peer="me",
            media=InputMediaUploadedDocument(
                file=input_file,
                mime_type="application/octet-stream",
                attributes=[DocumentAttributeFilename(os.path.basename(p))],
            ),
            message=f"ğŸ“¦ {original_name}\nğŸ—‚ Part {i}/{total}",
            random_id=random.randint(0, 2**63),
        ))
        safe_remove(p)
        await cb(f"âœ… **Part {i}/{total} done!**")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Single job processor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def process_one(url: str, status_msg):
    """
    Process single job.
    cb closure â€” status_msg passed as argument (no loop capture bug).
    """
    parts = []

    async def cb(text: str):
        try:
            await status_msg.edit(text)
        except:
            pass

    try:
        q_info = f"\nğŸ“‹ {len(job_queue)} in queue" if job_queue else ""
        await cb(f"ğŸ” Resolving...{q_info}")

        dl_url, fname, size, hdrs = resolve_gofile(url)
        await cb(
            f"ğŸ“„ **{fname}**\n"
            f"ğŸ’¾ {size//(1024**2)} MB\n\n"
            f"{make_bar(0)} 0%\n"
            f"â¬‡ï¸ Downloading...{q_info}"
        )

        path  = await download_file(dl_url, fname, hdrs, cb)
        parts = split_file(path)
        await upload_all_parts(parts, fname, cb)

        next_info = f"\n\nâ–¶ï¸ Next: `{job_queue[0][0]}`" if job_queue else ""
        await cb(
            f"ğŸ‰ **Done!**\n\n"
            f"ğŸ“¦ `{fname}`\n"
            f"ğŸ—‚ {len(parts)} part(s) â†’ Saved Messages"
            f"{next_info}"
        )

    except Exception as e:
        await cb(f"âŒ **Error:**\n`{e}`")

    finally:
        for p in parts:
            safe_remove(p)
        queue_urls.discard(url)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Queue worker â€” guaranteed single instance
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def queue_worker():
    """
    Single worker loop.
    job_queue à·™ items one by one process à¶šà¶»à¶±à·€à·.
    Worker done à·€à·”à¶±à·à¶¸ global worker_task = None.
    """
    global worker_task

    while job_queue:
        url, status_msg = job_queue.popleft()

        # Notify next if queued
        if job_queue:
            try:
                await job_queue[0][1].edit(
                    f"ğŸ“‹ **Queued #{len(job_queue)}**\n\n"
                    f"`{job_queue[0][0]}`\n\n"
                    f"â³ Current job à¶‰à·€à¶» à·€à·”à¶±à·à¶¸ start..."
                )
            except:
                pass

        await process_one(url, status_msg)

        # Notify next job starting
        if job_queue:
            try:
                await job_queue[0][1].edit(
                    f"â–¶ï¸ **Starting now!**\n`{job_queue[0][0]}`"
                )
            except:
                pass

        await asyncio.sleep(0.5)

    worker_task = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Bot handlers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@bot_client.on(events.NewMessage(pattern="/start"))
async def start_handler(event):
    await event.respond(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        "â•‘  ğŸ“¦ **GoFile Downloader**  â•‘\n"
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
        "ğŸš€ GoFile â†’ Telegram Saved Messages\n"
        f"âš¡ {CONCURRENT}x concurrent upload\n\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "ğŸ“ `https://gofile.io/d/XXXXXX`\n\n"
        "ğŸ“‹ Links à¶šà·’à·„à·’à¶´à¶ºà¶šà·Š â†’ auto queue\n"
        "ğŸ“Š /queue â€” status\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    )


@bot_client.on(events.NewMessage(pattern="/queue"))
async def queue_handler(event):
    if not job_queue and worker_task is None:
        return await event.respond("âœ… Queue empty â€” bot ready!")
    lines = [f"ğŸ“‹ **Queue** ({len(job_queue)} waiting)\n"]
    if worker_task is not None:
        lines.insert(1, "ğŸ”„ 1 job processing now\n")
    for i, (url, _) in enumerate(job_queue, 1):
        lines.append(f"{i}. `{url}`")
    await event.respond("\n".join(lines))


@bot_client.on(events.NewMessage(pattern=r"https://gofile\.io/d/\S+"))
async def gofile_handler(event):
    global worker_task

    url = event.pattern_match.group(0).strip()

    # Duplicate check
    if url in queue_urls:
        return await event.respond(f"âš ï¸ Already queued!\n`{url}`")

    queue_urls.add(url)

    pos = len(job_queue) + (1 if worker_task is not None else 0)

    if pos == 0:
        status_msg = await event.respond("ğŸ” Starting...")
    else:
        status_msg = await event.respond(
            f"ğŸ“‹ **Queued #{pos + 1}**\n\n"
            f"`{url}`\n\n"
            f"â³ {pos} job(s) à¶‰à·€à¶» à·€à·”à¶±à·à¶¸ start!"
        )

    job_queue.append((url, status_msg))

    # Single worker guarantee â€” already running à¶±à¶¸à·Š spawn à¶±à·œà¶šà¶»à¶ºà·’
    if worker_task is None or worker_task.done():
        worker_task = asyncio.create_task(queue_worker())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    await user_client.start()
    print("[âœ“] User client connected.")

    await bot_client.start(bot_token=BOT_TOKEN)
    me = await bot_client.get_me()
    print(f"[âœ“] Bot @{me.username} running!")
    print(f"[*] Concurrent chunks : {CONCURRENT}")
    print(f"[*] Part size         : {PART_SIZE//(1024**2)} MB")
    print("[*] Waiting for links...")

    await bot_client.run_until_disconnected()


if __name__ == "__main__":
    asyncio.run(main())